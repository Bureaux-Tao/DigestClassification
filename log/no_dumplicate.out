Using TensorFlow backend.
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.

WARNING:tensorflow:From /home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
Input-Token (InputLayer)        (None, None)         0
__________________________________________________________________________________________________
Input-Segment (InputLayer)      (None, None)         0
__________________________________________________________________________________________________
Embedding-Token (Embedding)     (None, None, 312)    6591936     Input-Token[0][0]
__________________________________________________________________________________________________
Embedding-Segment (Embedding)   (None, None, 312)    624         Input-Segment[0][0]
__________________________________________________________________________________________________
Embedding-Token-Segment (Add)   (None, None, 312)    0           Embedding-Token[0][0]
                                                                 Embedding-Segment[0][0]
__________________________________________________________________________________________________
Embedding-Position (PositionEmb (None, None, 312)    159744      Embedding-Token-Segment[0][0]
__________________________________________________________________________________________________
Embedding-Norm (LayerNormalizat (None, None, 312)    624         Embedding-Position[0][0]
__________________________________________________________________________________________________
Transformer-MultiHeadSelfAttent (None, None, 312)    390624      Embedding-Norm[0][0]
                                                                 Embedding-Norm[0][0]
                                                                 Embedding-Norm[0][0]
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-FeedForward-Norm[2][0
__________________________________________________________________________________________________
Transformer-MultiHeadSelfAttent (None, None, 312)    0           Embedding-Norm[0][0]
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-MultiHeadSelfAttentio
__________________________________________________________________________________________________
Transformer-MultiHeadSelfAttent (None, None, 312)    624         Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
__________________________________________________________________________________________________
Transformer-FeedForward (FeedFo (None, None, 312)    780312      Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
__________________________________________________________________________________________________
Transformer-FeedForward-Add (Ad (None, None, 312)    0           Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[0][0]
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[1][0]
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[2][0]
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[3][0]
__________________________________________________________________________________________________
Transformer-FeedForward-Norm (L (None, None, 312)    624         Transformer-FeedForward-Add[0][0]
                                                                 Transformer-FeedForward-Add[1][0]
                                                                 Transformer-FeedForward-Add[2][0]
                                                                 Transformer-FeedForward-Add[3][0]
__________________________________________________________________________________________________
CLS-token (Lambda)              (None, 312)          0           Transformer-FeedForward-Norm[3][0
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 3)            939         CLS-token[0][0]
==================================================================================================
Total params: 7,926,051
Trainable params: 7,926,051
Non-trainable params: 0
__________________________________________________________________________________________________
WARNING:tensorflow:From /home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /home/bureaux/miniconda3/envs/Keras-base/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where

batch_token_ids shape:  (128, 181)
batch_segment_ids shape: (128, 181)
batch_labels shape: (128, 1)

batch_token_ids shape:  (128, 159)
batch_segment_ids shape: (128, 159)
batch_labels shape: (128, 1)

batch_token_ids shape:  (128, 183)
batch_segment_ids shape: (128, 183)
batch_labels shape: (128, 1)

batch_token_ids shape:  (128, 177)
batch_segment_ids shape: (128, 177)
batch_labels shape: (128, 1)

batch_token_ids shape:  (128, 177)
batch_segment_ids shape: (128, 177)
batch_labels shape: (128, 1)

batch_token_ids shape:  (128, 174)
batch_segment_ids shape: (128, 174)
batch_labels shape: (128, 1)
Epoch 1/200
17/17 [==============================] - 33s 2s/step - loss: 1.2159 - sparse_categorical_accuracy: 0.2640 - val_loss: 1.0984 - val_sparse_categorical_accuracy: 0.4735
val_acc: 0.47348, best_val_acc: 0.47348, test_acc: 0.46989

Epoch 2/200
17/17 [==============================] - 13s 785ms/step - loss: 1.1914 - sparse_categorical_accuracy: 0.2299 - val_loss: 1.0803 - val_sparse_categorical_accuracy: 0.5265
val_acc: 0.52652, best_val_acc: 0.52652, test_acc: 0.49976

Epoch 3/200
17/17 [==============================] - 13s 777ms/step - loss: 1.1428 - sparse_categorical_accuracy: 0.2834 - val_loss: 1.0580 - val_sparse_categorical_accuracy: 0.5379
val_acc: 0.53788, best_val_acc: 0.53788, test_acc: 0.49644

Epoch 4/200
17/17 [==============================] - 13s 790ms/step - loss: 1.1165 - sparse_categorical_accuracy: 0.4294 - val_loss: 1.0362 - val_sparse_categorical_accuracy: 0.5303
val_acc: 0.53030, best_val_acc: 0.53788, test_acc: 0.49312

Epoch 5/200
17/17 [==============================] - 13s 785ms/step - loss: 1.0876 - sparse_categorical_accuracy: 0.4792 - val_loss: 1.0117 - val_sparse_categorical_accuracy: 0.5303
val_acc: 0.53030, best_val_acc: 0.53788, test_acc: 0.48791

Epoch 6/200
17/17 [==============================] - 13s 775ms/step - loss: 1.0576 - sparse_categorical_accuracy: 0.4737 - val_loss: 0.9949 - val_sparse_categorical_accuracy: 0.5265
val_acc: 0.52652, best_val_acc: 0.53788, test_acc: 0.48649

Epoch 7/200
17/17 [==============================] - 13s 779ms/step - loss: 1.0442 - sparse_categorical_accuracy: 0.4843 - val_loss: 0.9750 - val_sparse_categorical_accuracy: 0.5265
val_acc: 0.52652, best_val_acc: 0.53788, test_acc: 0.48649

Epoch 8/200
17/17 [==============================] - 14s 816ms/step - loss: 1.0306 - sparse_categorical_accuracy: 0.4842 - val_loss: 0.9530 - val_sparse_categorical_accuracy: 0.5265
val_acc: 0.52652, best_val_acc: 0.53788, test_acc: 0.48649

Epoch 9/200
17/17 [==============================] - 15s 890ms/step - loss: 1.0069 - sparse_categorical_accuracy: 0.4857 - val_loss: 0.9294 - val_sparse_categorical_accuracy: 0.5265
val_acc: 0.52652, best_val_acc: 0.53788, test_acc: 0.48696

Epoch 10/200
17/17 [==============================] - 16s 921ms/step - loss: 0.9953 - sparse_categorical_accuracy: 0.4922 - val_loss: 0.8991 - val_sparse_categorical_accuracy: 0.5265
val_acc: 0.52652, best_val_acc: 0.53788, test_acc: 0.48696

Epoch 11/200
17/17 [==============================] - 16s 935ms/step - loss: 0.9650 - sparse_categorical_accuracy: 0.4908 - val_loss: 0.8619 - val_sparse_categorical_accuracy: 0.5341
val_acc: 0.53409, best_val_acc: 0.53788, test_acc: 0.50640

Epoch 12/200
17/17 [==============================] - 17s 977ms/step - loss: 0.9145 - sparse_categorical_accuracy: 0.5125 - val_loss: 0.8046 - val_sparse_categorical_accuracy: 0.6174
val_acc: 0.61742, best_val_acc: 0.61742, test_acc: 0.57658

Epoch 13/200
17/17 [==============================] - 15s 863ms/step - loss: 0.8738 - sparse_categorical_accuracy: 0.5612 - val_loss: 0.7307 - val_sparse_categorical_accuracy: 0.7045
val_acc: 0.70455, best_val_acc: 0.70455, test_acc: 0.69180

Epoch 14/200
17/17 [==============================] - 17s 984ms/step - loss: 0.8083 - sparse_categorical_accuracy: 0.6534 - val_loss: 0.6383 - val_sparse_categorical_accuracy: 0.7765
val_acc: 0.77652, best_val_acc: 0.77652, test_acc: 0.78236

Epoch 15/200
17/17 [==============================] - 17s 1s/step - loss: 0.7120 - sparse_categorical_accuracy: 0.7361 - val_loss: 0.5269 - val_sparse_categorical_accuracy: 0.8864
val_acc: 0.88636, best_val_acc: 0.88636, test_acc: 0.89663

Epoch 16/200
17/17 [==============================] - 17s 1s/step - loss: 0.5975 - sparse_categorical_accuracy: 0.8004 - val_loss: 0.3960 - val_sparse_categorical_accuracy: 0.9470
val_acc: 0.94697, best_val_acc: 0.94697, test_acc: 0.95448

Epoch 17/200
17/17 [==============================] - 17s 1s/step - loss: 0.4368 - sparse_categorical_accuracy: 0.8977 - val_loss: 0.2626 - val_sparse_categorical_accuracy: 0.9659
val_acc: 0.96591, best_val_acc: 0.96591, test_acc: 0.97297

Epoch 18/200
17/17 [==============================] - 17s 1s/step - loss: 0.3064 - sparse_categorical_accuracy: 0.9512 - val_loss: 0.1821 - val_sparse_categorical_accuracy: 0.9697
val_acc: 0.96970, best_val_acc: 0.96970, test_acc: 0.97866

Epoch 19/200
17/17 [==============================] - 17s 1s/step - loss: 0.2110 - sparse_categorical_accuracy: 0.9645 - val_loss: 0.1383 - val_sparse_categorical_accuracy: 0.9735
val_acc: 0.97348, best_val_acc: 0.97348, test_acc: 0.98388

Epoch 20/200
17/17 [==============================] - 19s 1s/step - loss: 0.1642 - sparse_categorical_accuracy: 0.9714 - val_loss: 0.1089 - val_sparse_categorical_accuracy: 0.9848
val_acc: 0.98485, best_val_acc: 0.98485, test_acc: 0.98815

Epoch 21/200
17/17 [==============================] - 17s 1s/step - loss: 0.1324 - sparse_categorical_accuracy: 0.9723 - val_loss: 0.0920 - val_sparse_categorical_accuracy: 0.9848
val_acc: 0.98485, best_val_acc: 0.98485, test_acc: 0.98909

Epoch 22/200
17/17 [==============================] - 18s 1s/step - loss: 0.1093 - sparse_categorical_accuracy: 0.9811 - val_loss: 0.0781 - val_sparse_categorical_accuracy: 0.9848
val_acc: 0.98485, best_val_acc: 0.98485, test_acc: 0.99052

Epoch 23/200
17/17 [==============================] - 18s 1s/step - loss: 0.0927 - sparse_categorical_accuracy: 0.9866 - val_loss: 0.0702 - val_sparse_categorical_accuracy: 0.9848
val_acc: 0.98485, best_val_acc: 0.98485, test_acc: 0.99052

Epoch 24/200
17/17 [==============================] - 18s 1s/step - loss: 0.0905 - sparse_categorical_accuracy: 0.9861 - val_loss: 0.1014 - val_sparse_categorical_accuracy: 0.9848
val_acc: 0.98485, best_val_acc: 0.98485, test_acc: 0.99052

Epoch 25/200
17/17 [==============================] - 18s 1s/step - loss: 0.0818 - sparse_categorical_accuracy: 0.9866 - val_loss: 0.0601 - val_sparse_categorical_accuracy: 0.9886
val_acc: 0.98864, best_val_acc: 0.98864, test_acc: 0.99052

Epoch 26/200
17/17 [==============================] - 18s 1s/step - loss: 0.0715 - sparse_categorical_accuracy: 0.9889 - val_loss: 0.0569 - val_sparse_categorical_accuracy: 0.9848
val_acc: 0.98485, best_val_acc: 0.98864, test_acc: 0.99052

Epoch 27/200
17/17 [==============================] - 17s 1s/step - loss: 0.0636 - sparse_categorical_accuracy: 0.9894 - val_loss: 0.0535 - val_sparse_categorical_accuracy: 0.9886
val_acc: 0.98864, best_val_acc: 0.98864, test_acc: 0.99052

Epoch 28/200
17/17 [==============================] - 18s 1s/step - loss: 0.0617 - sparse_categorical_accuracy: 0.9889 - val_loss: 0.0506 - val_sparse_categorical_accuracy: 0.9886
val_acc: 0.98864, best_val_acc: 0.98864, test_acc: 0.99052

Epoch 29/200
17/17 [==============================] - 18s 1s/step - loss: 0.0558 - sparse_categorical_accuracy: 0.9899 - val_loss: 0.0471 - val_sparse_categorical_accuracy: 0.9886
val_acc: 0.98864, best_val_acc: 0.98864, test_acc: 0.99147

Epoch 30/200
17/17 [==============================] - 18s 1s/step - loss: 0.0526 - sparse_categorical_accuracy: 0.9899 - val_loss: 0.0442 - val_sparse_categorical_accuracy: 0.9886
val_acc: 0.98864, best_val_acc: 0.98864, test_acc: 0.99194

Epoch 31/200
17/17 [==============================] - 17s 1s/step - loss: 0.0485 - sparse_categorical_accuracy: 0.9913 - val_loss: 0.0403 - val_sparse_categorical_accuracy: 0.9886
val_acc: 0.98864, best_val_acc: 0.98864, test_acc: 0.99194

Epoch 32/200
17/17 [==============================] - 18s 1s/step - loss: 0.0449 - sparse_categorical_accuracy: 0.9926 - val_loss: 0.0383 - val_sparse_categorical_accuracy: 0.9886
val_acc: 0.98864, best_val_acc: 0.98864, test_acc: 0.99194

Epoch 33/200
17/17 [==============================] - 17s 1s/step - loss: 0.0425 - sparse_categorical_accuracy: 0.9926 - val_loss: 0.0369 - val_sparse_categorical_accuracy: 0.9886
val_acc: 0.98864, best_val_acc: 0.98864, test_acc: 0.99194

Epoch 34/200
17/17 [==============================] - 18s 1s/step - loss: 0.0391 - sparse_categorical_accuracy: 0.9926 - val_loss: 0.0337 - val_sparse_categorical_accuracy: 0.9886
val_acc: 0.98864, best_val_acc: 0.98864, test_acc: 0.99194

Epoch 35/200
17/17 [==============================] - 18s 1s/step - loss: 0.0362 - sparse_categorical_accuracy: 0.9922 - val_loss: 0.0302 - val_sparse_categorical_accuracy: 0.9886
val_acc: 0.98864, best_val_acc: 0.98864, test_acc: 0.99194

Epoch 36/200
17/17 [==============================] - 18s 1s/step - loss: 0.0332 - sparse_categorical_accuracy: 0.9931 - val_loss: 0.0345 - val_sparse_categorical_accuracy: 0.9886
val_acc: 0.98864, best_val_acc: 0.98864, test_acc: 0.99336

Epoch 37/200
17/17 [==============================] - 18s 1s/step - loss: 0.0307 - sparse_categorical_accuracy: 0.9935 - val_loss: 0.0219 - val_sparse_categorical_accuracy: 0.9924
val_acc: 0.99242, best_val_acc: 0.99242, test_acc: 0.99526

Epoch 38/200
17/17 [==============================] - 18s 1s/step - loss: 0.0263 - sparse_categorical_accuracy: 0.9945 - val_loss: 0.0184 - val_sparse_categorical_accuracy: 0.9962
val_acc: 0.99621, best_val_acc: 0.99621, test_acc: 0.99573

Epoch 39/200
17/17 [==============================] - 17s 1s/step - loss: 0.0282 - sparse_categorical_accuracy: 0.9935 - val_loss: 0.0158 - val_sparse_categorical_accuracy: 0.9962
val_acc: 0.99621, best_val_acc: 0.99621, test_acc: 0.99573

Epoch 40/200
17/17 [==============================] - 18s 1s/step - loss: 0.0239 - sparse_categorical_accuracy: 0.9963 - val_loss: 0.0162 - val_sparse_categorical_accuracy: 0.9962
val_acc: 0.99621, best_val_acc: 0.99621, test_acc: 0.99621

Epoch 41/200
17/17 [==============================] - 18s 1s/step - loss: 0.0202 - sparse_categorical_accuracy: 0.9963 - val_loss: 0.0166 - val_sparse_categorical_accuracy: 0.9962
val_acc: 0.99621, best_val_acc: 0.99621, test_acc: 0.99668

Epoch 42/200
17/17 [==============================] - 19s 1s/step - loss: 0.0193 - sparse_categorical_accuracy: 0.9972 - val_loss: 0.0117 - val_sparse_categorical_accuracy: 0.9962
val_acc: 0.99621, best_val_acc: 0.99621, test_acc: 0.99668

Epoch 43/200
17/17 [==============================] - 18s 1s/step - loss: 0.0166 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0112 - val_sparse_categorical_accuracy: 0.9962
val_acc: 0.99621, best_val_acc: 0.99621, test_acc: 0.99621

Epoch 44/200
17/17 [==============================] - 18s 1s/step - loss: 0.0154 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0097 - val_sparse_categorical_accuracy: 0.9962
val_acc: 0.99621, best_val_acc: 0.99621, test_acc: 0.99716

Epoch 45/200
17/17 [==============================] - 18s 1s/step - loss: 0.0133 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0088 - val_sparse_categorical_accuracy: 0.9962
val_acc: 0.99621, best_val_acc: 0.99621, test_acc: 0.99716

Epoch 46/200
17/17 [==============================] - 17s 1s/step - loss: 0.0128 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0087 - val_sparse_categorical_accuracy: 0.9962
val_acc: 0.99621, best_val_acc: 0.99621, test_acc: 0.99716

Epoch 47/200
17/17 [==============================] - 18s 1s/step - loss: 0.0117 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0079 - val_sparse_categorical_accuracy: 0.9962
val_acc: 0.99621, best_val_acc: 0.99621, test_acc: 0.99763

Epoch 48/200
17/17 [==============================] - 18s 1s/step - loss: 0.0109 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0078 - val_sparse_categorical_accuracy: 0.9962
val_acc: 0.99621, best_val_acc: 0.99621, test_acc: 0.99716

Epoch 49/200
17/17 [==============================] - 19s 1s/step - loss: 0.0103 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0072 - val_sparse_categorical_accuracy: 0.9962
val_acc: 0.99621, best_val_acc: 0.99621, test_acc: 0.99716

Epoch 50/200
17/17 [==============================] - 18s 1s/step - loss: 0.0091 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0063 - val_sparse_categorical_accuracy: 1.0000
val_acc: 1.00000, best_val_acc: 1.00000, test_acc: 0.99763